
PROCESSING:

- notebook d'inspection de la data propre
X- script concaténation x_data, y_data -> data: columns = ['text','img_path','labels']
X- repartition données d'entrainement, validation et non vue
X- fichier test + logs d'inspection du processing de la data: nb_product, text manquant, path manquant, data de type str...
X- suivi dvc/dagshub des csv : x_data, y_data, data, data_train, data_validation, data_unseen, poids des modèles
X- conteneur de preprocessing  

MODELISATION:

X- conteneur modèle
X- script d'inférence
X- DataLoader appliquant le pretraitement avant entrainement:
	- img
	- txt
- fichier test data loader
X- entrainement en local (1 epoch)
- suivi MLFLOW des paramètres d'entrainement + métriques + pondération par accuracy

INTERACTION:

- Fast-API init:
	- définition des entrypoints et de leurs exigences
	- connexion des scripts aux entrypoints
	- UI?
salut c'est moi